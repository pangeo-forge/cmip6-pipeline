{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook shows how to find URLs from ESGF\n",
    "- Choose an experiment_id, variable_id and table_id\n",
    "- Saves the URLs in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "import warnings\n",
    "import datetime\n",
    "import pprint\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esgf import esgf_search_sites, search, esgf_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load specified `zcs_id` from config file as well as I/O and ESGF specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit config.cfg to set local path (zarr_local) for saving search results\n",
    "\n",
    "config.read('config.cfg')\n",
    "zcs_dict = {}\n",
    "zcs_dict['activity_id'] = (config.get('zcs_id', 'activity_id'))\n",
    "zcs_dict['institution_id'] = config.get(\"zcs_id\", \"institution_id\")\n",
    "zcs_dict['source_id'] = config.get(\"zcs_id\", \"source_id\")\n",
    "zcs_dict['experiment_id'] = config.get(\"zcs_id\", \"experiment_id\")\n",
    "zcs_dict['member_id'] = config.get(\"zcs_id\", \"member_id\")\n",
    "zcs_dict['table_id'] = config.get(\"zcs_id\", \"table_id\")\n",
    "zcs_dict['variable_id'] = config.get(\"zcs_id\", \"variable_id\")\n",
    "zcs_dict['grid_label'] = config.get(\"zcs_id\", \"grid_label\")\n",
    "\n",
    "zarr_local = config.get(\"FILEPATHS\", \"zarr_local\")\n",
    "if not os.path.exists(zarr_local):\n",
    "    print('no such path')\n",
    "update_ESGF = config.getboolean(\"ESGF\", \"update_ESGF\")\n",
    "local_node = config.getboolean(\"ESGF\", \"local_node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible ESGF API search nodes:  ['llnl', 'ipsl', 'nci', 'ceda', 'gfdl', 'dkrz']\n",
      "setting current ESGF node to llnl\n"
     ]
    }
   ],
   "source": [
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')\n",
    "dtype = esgf_search_sites()\n",
    "print('possible ESGF API search nodes: ',list(dtype.keys()))\n",
    "node = 'llnl'\n",
    "print(\"setting current ESGF node to %s\" %node)\n",
    "ESGF_site = dtype[node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get what exists in GCS as zarr stores already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dGC = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores-noQC.csv', dtype={'version': 'unicode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_id': 'All',\n",
      " 'experiment_id': 'ssp370',\n",
      " 'grid_label': 'All',\n",
      " 'institution_id': 'All',\n",
      " 'member_id': 'All',\n",
      " 'source_id': 'All',\n",
      " 'table_id': 'day',\n",
      " 'variable_id': 'tasmax'}\n",
      "there are currently 8461 models in GCS for this specification\n"
     ]
    }
   ],
   "source": [
    "for key in zcs_dict:\n",
    "    if zcs_dict[key] != 'All':\n",
    "        dzLocal = dGC.loc[(dGC[key] == zcs_dict[key])]\n",
    "\n",
    "pprint.pprint(zcs_dict)\n",
    "print(\"there are currently %.0f models in GCS for this specification\" %len(dzLocal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dataframe of all matching ESGF datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370 tasmax day\n"
     ]
    }
   ],
   "source": [
    "if update_ESGF:\n",
    "    experiment_id = zcs_dict['experiment_id']\n",
    "    variable_id = zcs_dict['variable_id']\n",
    "    table_id = zcs_dict['table_id']\n",
    "    print(experiment_id,variable_id,table_id)\n",
    "    \n",
    "    dESGF = esgf_search(server=ESGF_site, mip_era='CMIP6', variable_id=variable_id, \n",
    "                           table_id=table_id, experiment_id=experiment_id, \n",
    "                           page_size=500, verbose=False, local_node=False)\n",
    "\n",
    "    dESGF.to_csv(os.path.join(zarr_local, 'ESGF_specific.csv'),index=False)\n",
    "else:\n",
    "    dESGF = pd.read_csv('csv/ESGF_specific.csv')\n",
    "    dESGF = dESGF.drop_duplicates(subset =[\"file_name\",\"version\",\"checksum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 datasets, consisting of 7297 netcdf files:\n"
     ]
    }
   ],
   "source": [
    "dESGF['zcs_id'] = [s.split('|')[0]for s in dESGF.dataset_id]\n",
    "zcs_ids = dESGF.zcs_id.unique()\n",
    "\n",
    "print('Found', dESGF.zcs_id.nunique(), 'datasets, consisting of',len(dESGF),'netcdf files:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_type is one of: Globus_url, GridFTP_url, HTTPServer_url, OPENDAP_url\n",
    "    \n",
    "def get_dataset_urls(dESGF,zcs_id,url_type='HTTPServer_url'):\n",
    "    df = dESGF[dESGF.zcs_id==zcs_id]\n",
    "    return sorted(df[url_type].values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20150101-20241231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20250101-20341231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20350101-20441231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20450101-20541231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20550101-20641231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20650101-20741231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20750101-20841231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20850101-20941231.nc', 'https://esgf-data1.llnl.gov/thredds/dodsC/css03_data/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/ssp370/r1i1p1f1/day/tasmax/gn/v20210323/tasmax_day_TaiESM1_ssp370_r1i1p1f1_gn_20950101-21001231.nc']\n"
     ]
    }
   ],
   "source": [
    "# Choose one with not too many netcdf files:\n",
    "\n",
    "zcs_id = zcs_ids[3]\n",
    "urls = get_dataset_urls(dESGF,zcs_id,url_type='OPENDAP_url')\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So now we have:\n",
    "\n",
    "- *zcs_ids*: list of all datasets corresponding to a given (experiment_id, variable_id, table_id) in the ESGF repository\n",
    "- *get_dataset_urls()*: list of urls for each dataset\n",
    "\n",
    "### To finish the pipeline, now we loop over zcs_ids:\n",
    "\n",
    "- if same dataset is already in GC, then skip (find_dataset()==True)  \n",
    "- download and cache the netcdfs needed for the dataset\n",
    "- pre-process and concatenate the dataset, fixing known problems, flagging new problems\n",
    "- if all is good, save the zarr to target location\n",
    "- update progress log (currently a Google Sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset is already in GC\n",
    "\n",
    "def find_dataset(dGC,zid):\n",
    "    zstore = '/'.join(zid.split('.'))[:-1] \n",
    "    dfz = dGC[dGC.zstore.str.contains(zstore)]\n",
    "    if len(dfz) >=1:\n",
    "        #print(zid,'same version already exists')\n",
    "        return True\n",
    "    vstore = '/'.join(zid.split('.')[:-1]) \n",
    "    dfv = dGC[dGC.zstore.str.contains(vstore)]\n",
    "    if len(dfv) >=1:\n",
    "        print(zid,'different version exists - maybe update?')\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMIP6.ScenarioMIP.AS-RCEC.TaiESM1.ssp370.r1i1p1f1.day.tasmax.gn.v20210323 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r11i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r12i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r13i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r14i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r15i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r16i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r17i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r18i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r19i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r20i1p1f1.day.tasmax.gn.v20210525 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r21i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r22i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r23i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r24i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r25i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r26i1p1f1.day.tasmax.gn.v20210618 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r27i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r28i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r29i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.CSIRO.ACCESS-ESM1-5.ssp370.r30i1p1f1.day.tasmax.gn.v20210617 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.EC-Earth-Consortium.EC-Earth3-Veg.ssp370.r12i1p1f1.day.tasmax.gr.v20200925 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.EC-Earth-Consortium.EC-Earth3-Veg.ssp370.r14i1p1f1.day.tasmax.gr.v20200925 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.NIMS-KMA.KACE-1-0-G.ssp370.r2i1p1f1.day.tasmax.gr.v20200102 different version exists - maybe update?\n",
      "CMIP6.ScenarioMIP.NIMS-KMA.KACE-1-0-G.ssp370.r3i1p1f1.day.tasmax.gr.v20200103 different version exists - maybe update?\n",
      "CMIP6.ScenarioMIP.NIMS-KMA.UKESM1-0-LL.ssp370.r13i1p1f2.day.tasmax.gn.v20210427 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.NIMS-KMA.UKESM1-0-LL.ssp370.r14i1p1f2.day.tasmax.gn.v20210428 Dataset is needed! Proceed with recipe\n",
      "CMIP6.ScenarioMIP.NIMS-KMA.UKESM1-0-LL.ssp370.r15i1p1f2.day.tasmax.gn.v20210428 Dataset is needed! Proceed with recipe\n"
     ]
    }
   ],
   "source": [
    "for zid in zcs_ids:\n",
    "    if find_dataset(dGC,zid):\n",
    "        continue\n",
    "    print(zid,'Dataset is needed! Proceed with recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-Jul2020",
   "language": "python",
   "name": "pangeo-jul2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
